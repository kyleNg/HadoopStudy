[WARN ][2017/08/03 00:02:5010 ][org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:62)]
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO ][2017/08/03 00:02:50676][org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1173)]
session.id is deprecated. Instead, use dfs.metrics.session-id
[INFO ][2017/08/03 00:02:50679][org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)]
Initializing JVM Metrics with processName=JobTracker, sessionId=
[WARN ][2017/08/03 00:02:51305][org.apache.hadoop.mapreduce.JobResourceUploader.uploadFiles(JobResourceUploader.java:64)]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
[WARN ][2017/08/03 00:02:51314][org.apache.hadoop.mapreduce.JobResourceUploader.uploadFiles(JobResourceUploader.java:171)]
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO ][2017/08/03 00:02:51361][org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:283)]
Total input paths to process : 1
[INFO ][2017/08/03 00:02:51493][org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)]
number of splits:1
[INFO ][2017/08/03 00:02:51824][org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:287)]
Submitting tokens for job: job_local1317267159_0001
[INFO ][2017/08/03 00:02:52239][org.apache.hadoop.mapreduce.Job.submit(Job.java:1294)]
The url to track the job: http://localhost:8080/
[INFO ][2017/08/03 00:02:52241][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1339)]
Running job: job_local1317267159_0001
[INFO ][2017/08/03 00:02:52242][org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)]
OutputCommitter set in config null
[INFO ][2017/08/03 00:02:52280][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:108)]
File Output Committer Algorithm version is 1
[INFO ][2017/08/03 00:02:52286][org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)]
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO ][2017/08/03 00:02:52418][org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)]
Waiting for map tasks
[INFO ][2017/08/03 00:02:52420][org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)]
Starting task: attempt_local1317267159_0001_m_000000_0
[INFO ][2017/08/03 00:02:52498][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:108)]
File Output Committer Algorithm version is 1
[INFO ][2017/08/03 00:02:52548][org.apache.hadoop.mapred.Task.initialize(Task.java:612)]
 Using ResourceCalculatorProcessTree : [ ]
[INFO ][2017/08/03 00:02:52631][org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:756)]
Processing split: file:/home/testuser/eclipse-workspace/HadoopStudy/HadoopStudy/TestData/flowoutput/part-r-00000:0+559
[INFO ][2017/08/03 00:02:5365 ][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1205)]
(EQUATOR) 0 kvi 26214396(104857584)
[INFO ][2017/08/03 00:02:5368 ][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)]
mapreduce.task.io.sort.mb: 100
[INFO ][2017/08/03 00:02:5368 ][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:999)]
soft limit at 83886080
[INFO ][2017/08/03 00:02:5369 ][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1000)]
bufstart = 0; bufvoid = 104857600
[INFO ][2017/08/03 00:02:5369 ][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1001)]
kvstart = 26214396; length = 6553600
[INFO ][2017/08/03 00:02:5379 ][org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:403)]
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO ][2017/08/03 00:02:5482 ][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1360)]
Job job_local1317267159_0001 running in uber mode : false
[INFO ][2017/08/03 00:03:2295 ][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1367)]
 map 0% reduce 0%
[INFO ][2017/08/03 00:05:05537][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
map > map
[INFO ][2017/08/03 00:05:47780][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1367)]
 map 3% reduce 0%
[INFO ][2017/08/03 00:08:36258][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
map > map
[INFO ][2017/08/03 00:09:39525][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
map > map
[INFO ][2017/08/03 00:09:42969][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1367)]
 map 7% reduce 0%
[INFO ][2017/08/03 00:10:46980][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
map > map
[INFO ][2017/08/03 00:10:46981][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1367)]
 map 20% reduce 0%
[INFO ][2017/08/03 00:10:53173][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
map > map
[INFO ][2017/08/03 00:10:58947][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
map > map
[INFO ][2017/08/03 00:14:4675 ][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
map > map
[INFO ][2017/08/03 00:14:4697 ][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
map > map
[INFO ][2017/08/03 00:14:46101][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1460)]
Starting flush of map output
[INFO ][2017/08/03 00:14:46101][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1482)]
Spilling map output
[INFO ][2017/08/03 00:14:46101][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1483)]
bufstart = 0; bufend = 606; bufvoid = 104857600
[INFO ][2017/08/03 00:14:46101][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1485)]
kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
[INFO ][2017/08/03 00:14:46149][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1667)]
Finished spill 0
[INFO ][2017/08/03 00:14:46156][org.apache.hadoop.mapred.Task.done(Task.java:1038)]
Task:attempt_local1317267159_0001_m_000000_0 is done. And is in the process of committing
[INFO ][2017/08/03 00:14:46165][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
map
[INFO ][2017/08/03 00:14:46165][org.apache.hadoop.mapred.Task.sendDone(Task.java:1158)]
Task 'attempt_local1317267159_0001_m_000000_0' done.
[INFO ][2017/08/03 00:14:46166][org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)]
Finishing task: attempt_local1317267159_0001_m_000000_0
[INFO ][2017/08/03 00:14:46166][org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)]
map task executor complete.
[INFO ][2017/08/03 00:14:46190][org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)]
Waiting for reduce tasks
[INFO ][2017/08/03 00:14:46191][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)]
Starting task: attempt_local1317267159_0001_r_000000_0
[INFO ][2017/08/03 00:14:46244][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:108)]
File Output Committer Algorithm version is 1
[INFO ][2017/08/03 00:14:46245][org.apache.hadoop.mapred.Task.initialize(Task.java:612)]
 Using ResourceCalculatorProcessTree : [ ]
[INFO ][2017/08/03 00:14:46253][org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)]
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@67aaeae
[INFO ][2017/08/03 00:14:46344][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:197)]
MergerManager: memoryLimit=492149152, maxSingleShuffleLimit=123037288, mergeThreshold=324818464, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO ][2017/08/03 00:14:46381][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)]
attempt_local1317267159_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO ][2017/08/03 00:14:46511][org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:144)]
localfetcher#1 about to shuffle output of map attempt_local1317267159_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
[INFO ][2017/08/03 00:14:46537][org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)]
Read 2 bytes from map-output for attempt_local1317267159_0001_m_000000_0
[INFO ][2017/08/03 00:14:46560][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:315)]
closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
[INFO ][2017/08/03 00:14:46570][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)]
EventFetcher is interrupted.. Returning
[INFO ][2017/08/03 00:14:46572][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:14:46573][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:687)]
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO ][2017/08/03 00:14:46588][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:14:46593][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 0 segments left of total size: 0 bytes
[INFO ][2017/08/03 00:14:46600][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:754)]
Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
[INFO ][2017/08/03 00:14:46601][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:784)]
Merging 1 files, 6 bytes from disk
[INFO ][2017/08/03 00:14:46602][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:799)]
Merging 0 segments, 0 bytes from memory into reduce
[INFO ][2017/08/03 00:14:46602][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:14:46603][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 0 segments left of total size: 0 bytes
[INFO ][2017/08/03 00:14:46604][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:14:46658][org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1173)]
mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
[INFO ][2017/08/03 00:14:46672][org.apache.hadoop.mapred.Task.done(Task.java:1038)]
Task:attempt_local1317267159_0001_r_000000_0 is done. And is in the process of committing
[INFO ][2017/08/03 00:14:46674][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:14:46674][org.apache.hadoop.mapred.Task.commit(Task.java:1199)]
Task attempt_local1317267159_0001_r_000000_0 is allowed to commit now
[INFO ][2017/08/03 00:14:46678][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:535)]
Saved output of task 'attempt_local1317267159_0001_r_000000_0' to file:/home/testuser/eclipse-workspace/HadoopStudy/HadoopStudy/TestData/provinceOutput/_temporary/0/task_local1317267159_0001_r_000000
[INFO ][2017/08/03 00:14:46682][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
reduce > reduce
[INFO ][2017/08/03 00:14:46682][org.apache.hadoop.mapred.Task.sendDone(Task.java:1158)]
Task 'attempt_local1317267159_0001_r_000000_0' done.
[INFO ][2017/08/03 00:14:46682][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)]
Finishing task: attempt_local1317267159_0001_r_000000_0
[INFO ][2017/08/03 00:14:46683][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)]
Starting task: attempt_local1317267159_0001_r_000001_0
[INFO ][2017/08/03 00:14:46687][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:108)]
File Output Committer Algorithm version is 1
[INFO ][2017/08/03 00:14:46688][org.apache.hadoop.mapred.Task.initialize(Task.java:612)]
 Using ResourceCalculatorProcessTree : [ ]
[INFO ][2017/08/03 00:14:46688][org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)]
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1367e68b
[INFO ][2017/08/03 00:14:46689][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:197)]
MergerManager: memoryLimit=492149152, maxSingleShuffleLimit=123037288, mergeThreshold=324818464, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO ][2017/08/03 00:14:46692][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)]
attempt_local1317267159_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO ][2017/08/03 00:14:46700][org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:144)]
localfetcher#2 about to shuffle output of map attempt_local1317267159_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
[INFO ][2017/08/03 00:14:46701][org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)]
Read 2 bytes from map-output for attempt_local1317267159_0001_m_000000_0
[INFO ][2017/08/03 00:14:46702][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:315)]
closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
[INFO ][2017/08/03 00:14:46703][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)]
EventFetcher is interrupted.. Returning
[INFO ][2017/08/03 00:14:46704][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:14:46705][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:687)]
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO ][2017/08/03 00:14:46707][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:14:46710][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 0 segments left of total size: 0 bytes
[INFO ][2017/08/03 00:14:46711][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:754)]
Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
[INFO ][2017/08/03 00:14:46711][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:784)]
Merging 1 files, 6 bytes from disk
[INFO ][2017/08/03 00:14:46711][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:799)]
Merging 0 segments, 0 bytes from memory into reduce
[INFO ][2017/08/03 00:14:46711][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:14:46715][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 0 segments left of total size: 0 bytes
[INFO ][2017/08/03 00:14:46716][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:14:46731][org.apache.hadoop.mapred.Task.done(Task.java:1038)]
Task:attempt_local1317267159_0001_r_000001_0 is done. And is in the process of committing
[INFO ][2017/08/03 00:14:46733][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:14:46733][org.apache.hadoop.mapred.Task.commit(Task.java:1199)]
Task attempt_local1317267159_0001_r_000001_0 is allowed to commit now
[INFO ][2017/08/03 00:14:46736][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:535)]
Saved output of task 'attempt_local1317267159_0001_r_000001_0' to file:/home/testuser/eclipse-workspace/HadoopStudy/HadoopStudy/TestData/provinceOutput/_temporary/0/task_local1317267159_0001_r_000001
[INFO ][2017/08/03 00:14:46738][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
reduce > reduce
[INFO ][2017/08/03 00:14:46739][org.apache.hadoop.mapred.Task.sendDone(Task.java:1158)]
Task 'attempt_local1317267159_0001_r_000001_0' done.
[INFO ][2017/08/03 00:14:46739][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)]
Finishing task: attempt_local1317267159_0001_r_000001_0
[INFO ][2017/08/03 00:14:46740][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)]
Starting task: attempt_local1317267159_0001_r_000002_0
[INFO ][2017/08/03 00:14:46743][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:108)]
File Output Committer Algorithm version is 1
[INFO ][2017/08/03 00:14:46744][org.apache.hadoop.mapred.Task.initialize(Task.java:612)]
 Using ResourceCalculatorProcessTree : [ ]
[INFO ][2017/08/03 00:14:46744][org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)]
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@f99e6bb
[INFO ][2017/08/03 00:14:46757][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:197)]
MergerManager: memoryLimit=492149152, maxSingleShuffleLimit=123037288, mergeThreshold=324818464, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO ][2017/08/03 00:14:46759][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)]
attempt_local1317267159_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO ][2017/08/03 00:14:46776][org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:144)]
localfetcher#3 about to shuffle output of map attempt_local1317267159_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
[INFO ][2017/08/03 00:14:46776][org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)]
Read 2 bytes from map-output for attempt_local1317267159_0001_m_000000_0
[INFO ][2017/08/03 00:14:46776][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:315)]
closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
[INFO ][2017/08/03 00:14:46780][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)]
EventFetcher is interrupted.. Returning
[INFO ][2017/08/03 00:14:46781][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:14:46781][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:687)]
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO ][2017/08/03 00:14:46782][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:14:46783][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 0 segments left of total size: 0 bytes
[INFO ][2017/08/03 00:14:46783][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:754)]
Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
[INFO ][2017/08/03 00:14:46784][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:784)]
Merging 1 files, 6 bytes from disk
[INFO ][2017/08/03 00:14:46784][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:799)]
Merging 0 segments, 0 bytes from memory into reduce
[INFO ][2017/08/03 00:14:46784][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:14:46785][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 0 segments left of total size: 0 bytes
[INFO ][2017/08/03 00:14:46785][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:14:46798][org.apache.hadoop.mapred.Task.done(Task.java:1038)]
Task:attempt_local1317267159_0001_r_000002_0 is done. And is in the process of committing
[INFO ][2017/08/03 00:14:46799][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:14:46801][org.apache.hadoop.mapred.Task.commit(Task.java:1199)]
Task attempt_local1317267159_0001_r_000002_0 is allowed to commit now
[INFO ][2017/08/03 00:14:46802][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:535)]
Saved output of task 'attempt_local1317267159_0001_r_000002_0' to file:/home/testuser/eclipse-workspace/HadoopStudy/HadoopStudy/TestData/provinceOutput/_temporary/0/task_local1317267159_0001_r_000002
[INFO ][2017/08/03 00:14:46810][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
reduce > reduce
[INFO ][2017/08/03 00:14:46810][org.apache.hadoop.mapred.Task.sendDone(Task.java:1158)]
Task 'attempt_local1317267159_0001_r_000002_0' done.
[INFO ][2017/08/03 00:14:46810][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)]
Finishing task: attempt_local1317267159_0001_r_000002_0
[INFO ][2017/08/03 00:14:46810][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)]
Starting task: attempt_local1317267159_0001_r_000003_0
[INFO ][2017/08/03 00:14:46812][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:108)]
File Output Committer Algorithm version is 1
[INFO ][2017/08/03 00:14:46813][org.apache.hadoop.mapred.Task.initialize(Task.java:612)]
 Using ResourceCalculatorProcessTree : [ ]
[INFO ][2017/08/03 00:14:46813][org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)]
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7e2f3157
[INFO ][2017/08/03 00:14:46814][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:197)]
MergerManager: memoryLimit=492149152, maxSingleShuffleLimit=123037288, mergeThreshold=324818464, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO ][2017/08/03 00:14:46819][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)]
attempt_local1317267159_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO ][2017/08/03 00:14:46823][org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:144)]
localfetcher#4 about to shuffle output of map attempt_local1317267159_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
[INFO ][2017/08/03 00:14:46824][org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)]
Read 2 bytes from map-output for attempt_local1317267159_0001_m_000000_0
[INFO ][2017/08/03 00:14:46825][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:315)]
closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
[INFO ][2017/08/03 00:14:46826][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)]
EventFetcher is interrupted.. Returning
[INFO ][2017/08/03 00:14:46828][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:14:46828][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:687)]
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO ][2017/08/03 00:14:46830][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:14:46834][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 0 segments left of total size: 0 bytes
[INFO ][2017/08/03 00:14:46835][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:754)]
Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
[INFO ][2017/08/03 00:14:46836][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:784)]
Merging 1 files, 6 bytes from disk
[INFO ][2017/08/03 00:14:46836][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:799)]
Merging 0 segments, 0 bytes from memory into reduce
[INFO ][2017/08/03 00:14:46836][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:14:46836][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 0 segments left of total size: 0 bytes
[INFO ][2017/08/03 00:14:46837][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:14:46849][org.apache.hadoop.mapred.Task.done(Task.java:1038)]
Task:attempt_local1317267159_0001_r_000003_0 is done. And is in the process of committing
[INFO ][2017/08/03 00:14:46851][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:14:46851][org.apache.hadoop.mapred.Task.commit(Task.java:1199)]
Task attempt_local1317267159_0001_r_000003_0 is allowed to commit now
[INFO ][2017/08/03 00:14:46851][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:535)]
Saved output of task 'attempt_local1317267159_0001_r_000003_0' to file:/home/testuser/eclipse-workspace/HadoopStudy/HadoopStudy/TestData/provinceOutput/_temporary/0/task_local1317267159_0001_r_000003
[INFO ][2017/08/03 00:14:46861][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
reduce > reduce
[INFO ][2017/08/03 00:14:46861][org.apache.hadoop.mapred.Task.sendDone(Task.java:1158)]
Task 'attempt_local1317267159_0001_r_000003_0' done.
[INFO ][2017/08/03 00:14:46862][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)]
Finishing task: attempt_local1317267159_0001_r_000003_0
[INFO ][2017/08/03 00:14:46864][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)]
Starting task: attempt_local1317267159_0001_r_000004_0
[INFO ][2017/08/03 00:14:46867][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:108)]
File Output Committer Algorithm version is 1
[INFO ][2017/08/03 00:14:46868][org.apache.hadoop.mapred.Task.initialize(Task.java:612)]
 Using ResourceCalculatorProcessTree : [ ]
[INFO ][2017/08/03 00:14:46868][org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)]
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@48b57727
[INFO ][2017/08/03 00:14:46870][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:197)]
MergerManager: memoryLimit=492149152, maxSingleShuffleLimit=123037288, mergeThreshold=324818464, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO ][2017/08/03 00:14:46876][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)]
attempt_local1317267159_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO ][2017/08/03 00:14:46886][org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:144)]
localfetcher#5 about to shuffle output of map attempt_local1317267159_0001_m_000000_0 decomp: 650 len: 654 to MEMORY
[INFO ][2017/08/03 00:14:46889][org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)]
Read 650 bytes from map-output for attempt_local1317267159_0001_m_000000_0
[INFO ][2017/08/03 00:14:46889][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:315)]
closeInMemoryFile -> map-output of size: 650, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->650
[INFO ][2017/08/03 00:14:46898][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)]
EventFetcher is interrupted.. Returning
[INFO ][2017/08/03 00:14:46900][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:14:46901][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:687)]
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO ][2017/08/03 00:14:46902][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:14:46903][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 1 segments left of total size: 642 bytes
[INFO ][2017/08/03 00:14:46906][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:754)]
Merged 1 segments, 650 bytes to disk to satisfy reduce memory limit
[INFO ][2017/08/03 00:14:46907][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:784)]
Merging 1 files, 654 bytes from disk
[INFO ][2017/08/03 00:14:46907][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:799)]
Merging 0 segments, 0 bytes from memory into reduce
[INFO ][2017/08/03 00:14:46907][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:14:46908][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 1 segments left of total size: 642 bytes
[INFO ][2017/08/03 00:14:46912][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:15:03587][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1367)]
 map 100% reduce 80%
[INFO ][2017/08/03 00:16:20866][org.apache.hadoop.mapred.Task.done(Task.java:1038)]
Task:attempt_local1317267159_0001_r_000004_0 is done. And is in the process of committing
[INFO ][2017/08/03 00:16:20870][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
reduce > reduce
[INFO ][2017/08/03 00:16:20871][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
reduce > reduce
[INFO ][2017/08/03 00:16:20871][org.apache.hadoop.mapred.Task.commit(Task.java:1199)]
Task attempt_local1317267159_0001_r_000004_0 is allowed to commit now
[INFO ][2017/08/03 00:16:20872][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:535)]
Saved output of task 'attempt_local1317267159_0001_r_000004_0' to file:/home/testuser/eclipse-workspace/HadoopStudy/HadoopStudy/TestData/provinceOutput/_temporary/0/task_local1317267159_0001_r_000004
[INFO ][2017/08/03 00:16:20882][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
reduce > reduce
[INFO ][2017/08/03 00:16:20882][org.apache.hadoop.mapred.Task.sendDone(Task.java:1158)]
Task 'attempt_local1317267159_0001_r_000004_0' done.
[INFO ][2017/08/03 00:16:20882][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)]
Finishing task: attempt_local1317267159_0001_r_000004_0
[INFO ][2017/08/03 00:16:20883][org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)]
reduce task executor complete.
[INFO ][2017/08/03 00:16:21872][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1367)]
 map 100% reduce 100%
[INFO ][2017/08/03 00:16:21874][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1378)]
Job job_local1317267159_0001 completed successfully
[INFO ][2017/08/03 00:16:21920][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1385)]
Counters: 30
	File System Counters
		FILE: Number of bytes read=17472
		FILE: Number of bytes written=1729235
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=21
		Map output records=21
		Map output bytes=606
		Map output materialized bytes=678
		Input split bytes=159
		Combine input records=0
		Combine output records=0
		Reduce input groups=19
		Reduce shuffle bytes=678
		Reduce input records=21
		Reduce output records=19
		Spilled Records=42
		Shuffled Maps =5
		Failed Shuffles=0
		Merged Map outputs=5
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=1132986368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=579
	File Output Format Counters 
		Bytes Written=423
[WARN ][2017/08/03 00:17:42390][org.apache.hadoop.util.NativeCodeLoader.<clinit>(NativeCodeLoader.java:62)]
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO ][2017/08/03 00:17:43714][org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1173)]
session.id is deprecated. Instead, use dfs.metrics.session-id
[INFO ][2017/08/03 00:17:43718][org.apache.hadoop.metrics.jvm.JvmMetrics.init(JvmMetrics.java:76)]
Initializing JVM Metrics with processName=JobTracker, sessionId=
[WARN ][2017/08/03 00:17:44329][org.apache.hadoop.mapreduce.JobResourceUploader.uploadFiles(JobResourceUploader.java:64)]
Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
[WARN ][2017/08/03 00:17:44335][org.apache.hadoop.mapreduce.JobResourceUploader.uploadFiles(JobResourceUploader.java:171)]
No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
[INFO ][2017/08/03 00:17:44370][org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:283)]
Total input paths to process : 1
[INFO ][2017/08/03 00:17:44490][org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)]
number of splits:1
[INFO ][2017/08/03 00:17:44694][org.apache.hadoop.mapreduce.JobSubmitter.printTokens(JobSubmitter.java:287)]
Submitting tokens for job: job_local913227038_0001
[INFO ][2017/08/03 00:17:44872][org.apache.hadoop.mapreduce.Job.submit(Job.java:1294)]
The url to track the job: http://localhost:8080/
[INFO ][2017/08/03 00:17:44873][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1339)]
Running job: job_local913227038_0001
[INFO ][2017/08/03 00:17:44878][org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:471)]
OutputCommitter set in config null
[INFO ][2017/08/03 00:17:44887][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:108)]
File Output Committer Algorithm version is 1
[INFO ][2017/08/03 00:17:44897][org.apache.hadoop.mapred.LocalJobRunner$Job.createOutputCommitter(LocalJobRunner.java:489)]
OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[INFO ][2017/08/03 00:17:4529 ][org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)]
Waiting for map tasks
[INFO ][2017/08/03 00:17:4533 ][org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:224)]
Starting task: attempt_local913227038_0001_m_000000_0
[INFO ][2017/08/03 00:17:45105][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:108)]
File Output Committer Algorithm version is 1
[INFO ][2017/08/03 00:17:45160][org.apache.hadoop.mapred.Task.initialize(Task.java:612)]
 Using ResourceCalculatorProcessTree : [ ]
[INFO ][2017/08/03 00:17:45175][org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:756)]
Processing split: file:/home/testuser/eclipse-workspace/HadoopStudy/HadoopStudy/TestData/flowoutput/part-r-00000:0+559
[INFO ][2017/08/03 00:17:45427][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.setEquator(MapTask.java:1205)]
(EQUATOR) 0 kvi 26214396(104857584)
[INFO ][2017/08/03 00:17:45427][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:998)]
mapreduce.task.io.sort.mb: 100
[INFO ][2017/08/03 00:17:45428][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:999)]
soft limit at 83886080
[INFO ][2017/08/03 00:17:45428][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1000)]
bufstart = 0; bufvoid = 104857600
[INFO ][2017/08/03 00:17:45428][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1001)]
kvstart = 26214396; length = 6553600
[INFO ][2017/08/03 00:17:45436][org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:403)]
Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
[INFO ][2017/08/03 00:17:45457][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]

[INFO ][2017/08/03 00:17:45458][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1460)]
Starting flush of map output
[INFO ][2017/08/03 00:17:45458][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1482)]
Spilling map output
[INFO ][2017/08/03 00:17:45458][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1483)]
bufstart = 0; bufend = 753; bufvoid = 104857600
[INFO ][2017/08/03 00:17:45458][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1485)]
kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
[INFO ][2017/08/03 00:17:45471][org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1667)]
Finished spill 0
[INFO ][2017/08/03 00:17:45476][org.apache.hadoop.mapred.Task.done(Task.java:1038)]
Task:attempt_local913227038_0001_m_000000_0 is done. And is in the process of committing
[INFO ][2017/08/03 00:17:45487][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
map
[INFO ][2017/08/03 00:17:45488][org.apache.hadoop.mapred.Task.sendDone(Task.java:1158)]
Task 'attempt_local913227038_0001_m_000000_0' done.
[INFO ][2017/08/03 00:17:45489][org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:249)]
Finishing task: attempt_local913227038_0001_m_000000_0
[INFO ][2017/08/03 00:17:45490][org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)]
map task executor complete.
[INFO ][2017/08/03 00:17:45495][org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:448)]
Waiting for reduce tasks
[INFO ][2017/08/03 00:17:45497][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)]
Starting task: attempt_local913227038_0001_r_000000_0
[INFO ][2017/08/03 00:17:45510][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:108)]
File Output Committer Algorithm version is 1
[INFO ][2017/08/03 00:17:45511][org.apache.hadoop.mapred.Task.initialize(Task.java:612)]
 Using ResourceCalculatorProcessTree : [ ]
[INFO ][2017/08/03 00:17:45523][org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)]
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@533b1667
[INFO ][2017/08/03 00:17:45547][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:197)]
MergerManager: memoryLimit=492149152, maxSingleShuffleLimit=123037288, mergeThreshold=324818464, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO ][2017/08/03 00:17:45567][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)]
attempt_local913227038_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO ][2017/08/03 00:17:45823][org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:144)]
localfetcher#1 about to shuffle output of map attempt_local913227038_0001_m_000000_0 decomp: 78 len: 82 to MEMORY
[INFO ][2017/08/03 00:17:45826][org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)]
Read 78 bytes from map-output for attempt_local913227038_0001_m_000000_0
[INFO ][2017/08/03 00:17:45856][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:315)]
closeInMemoryFile -> map-output of size: 78, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->78
[INFO ][2017/08/03 00:17:45862][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)]
EventFetcher is interrupted.. Returning
[INFO ][2017/08/03 00:17:45863][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:45864][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:687)]
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO ][2017/08/03 00:17:45876][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1360)]
Job job_local913227038_0001 running in uber mode : false
[INFO ][2017/08/03 00:17:45877][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1367)]
 map 100% reduce 0%
[INFO ][2017/08/03 00:17:45909][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:17:45909][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 1 segments left of total size: 64 bytes
[INFO ][2017/08/03 00:17:45914][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:754)]
Merged 1 segments, 78 bytes to disk to satisfy reduce memory limit
[INFO ][2017/08/03 00:17:45915][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:784)]
Merging 1 files, 82 bytes from disk
[INFO ][2017/08/03 00:17:45916][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:799)]
Merging 0 segments, 0 bytes from memory into reduce
[INFO ][2017/08/03 00:17:45916][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:17:45917][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 1 segments left of total size: 64 bytes
[INFO ][2017/08/03 00:17:45922][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:45956][org.apache.hadoop.conf.Configuration.warnOnceIfDeprecated(Configuration.java:1173)]
mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
[INFO ][2017/08/03 00:17:45967][org.apache.hadoop.mapred.Task.done(Task.java:1038)]
Task:attempt_local913227038_0001_r_000000_0 is done. And is in the process of committing
[INFO ][2017/08/03 00:17:45968][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:45969][org.apache.hadoop.mapred.Task.commit(Task.java:1199)]
Task attempt_local913227038_0001_r_000000_0 is allowed to commit now
[INFO ][2017/08/03 00:17:45973][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:535)]
Saved output of task 'attempt_local913227038_0001_r_000000_0' to file:/home/testuser/eclipse-workspace/HadoopStudy/HadoopStudy/TestData/provinceOutput/_temporary/0/task_local913227038_0001_r_000000
[INFO ][2017/08/03 00:17:45974][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
reduce > reduce
[INFO ][2017/08/03 00:17:45975][org.apache.hadoop.mapred.Task.sendDone(Task.java:1158)]
Task 'attempt_local913227038_0001_r_000000_0' done.
[INFO ][2017/08/03 00:17:45977][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)]
Finishing task: attempt_local913227038_0001_r_000000_0
[INFO ][2017/08/03 00:17:45977][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)]
Starting task: attempt_local913227038_0001_r_000001_0
[INFO ][2017/08/03 00:17:4611 ][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:108)]
File Output Committer Algorithm version is 1
[INFO ][2017/08/03 00:17:4612 ][org.apache.hadoop.mapred.Task.initialize(Task.java:612)]
 Using ResourceCalculatorProcessTree : [ ]
[INFO ][2017/08/03 00:17:4612 ][org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)]
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@46e3ea01
[INFO ][2017/08/03 00:17:4616 ][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:197)]
MergerManager: memoryLimit=492149152, maxSingleShuffleLimit=123037288, mergeThreshold=324818464, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO ][2017/08/03 00:17:4651 ][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)]
attempt_local913227038_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO ][2017/08/03 00:17:4666 ][org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:144)]
localfetcher#2 about to shuffle output of map attempt_local913227038_0001_m_000000_0 decomp: 154 len: 158 to MEMORY
[INFO ][2017/08/03 00:17:4670 ][org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)]
Read 154 bytes from map-output for attempt_local913227038_0001_m_000000_0
[INFO ][2017/08/03 00:17:4678 ][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:315)]
closeInMemoryFile -> map-output of size: 154, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->154
[INFO ][2017/08/03 00:17:4681 ][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)]
EventFetcher is interrupted.. Returning
[INFO ][2017/08/03 00:17:4682 ][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:4683 ][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:687)]
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO ][2017/08/03 00:17:4684 ][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:17:4684 ][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 1 segments left of total size: 140 bytes
[INFO ][2017/08/03 00:17:4692 ][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:754)]
Merged 1 segments, 154 bytes to disk to satisfy reduce memory limit
[INFO ][2017/08/03 00:17:4693 ][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:784)]
Merging 1 files, 158 bytes from disk
[INFO ][2017/08/03 00:17:4693 ][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:799)]
Merging 0 segments, 0 bytes from memory into reduce
[INFO ][2017/08/03 00:17:4693 ][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:17:4694 ][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 1 segments left of total size: 140 bytes
[INFO ][2017/08/03 00:17:4694 ][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:46149][org.apache.hadoop.mapred.Task.done(Task.java:1038)]
Task:attempt_local913227038_0001_r_000001_0 is done. And is in the process of committing
[INFO ][2017/08/03 00:17:46151][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:46151][org.apache.hadoop.mapred.Task.commit(Task.java:1199)]
Task attempt_local913227038_0001_r_000001_0 is allowed to commit now
[INFO ][2017/08/03 00:17:46152][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:535)]
Saved output of task 'attempt_local913227038_0001_r_000001_0' to file:/home/testuser/eclipse-workspace/HadoopStudy/HadoopStudy/TestData/provinceOutput/_temporary/0/task_local913227038_0001_r_000001
[INFO ][2017/08/03 00:17:46154][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
reduce > reduce
[INFO ][2017/08/03 00:17:46154][org.apache.hadoop.mapred.Task.sendDone(Task.java:1158)]
Task 'attempt_local913227038_0001_r_000001_0' done.
[INFO ][2017/08/03 00:17:46154][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)]
Finishing task: attempt_local913227038_0001_r_000001_0
[INFO ][2017/08/03 00:17:46154][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)]
Starting task: attempt_local913227038_0001_r_000002_0
[INFO ][2017/08/03 00:17:46173][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:108)]
File Output Committer Algorithm version is 1
[INFO ][2017/08/03 00:17:46174][org.apache.hadoop.mapred.Task.initialize(Task.java:612)]
 Using ResourceCalculatorProcessTree : [ ]
[INFO ][2017/08/03 00:17:46175][org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)]
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@78dd1df8
[INFO ][2017/08/03 00:17:46179][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:197)]
MergerManager: memoryLimit=492149152, maxSingleShuffleLimit=123037288, mergeThreshold=324818464, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO ][2017/08/03 00:17:46196][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)]
attempt_local913227038_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO ][2017/08/03 00:17:46217][org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:144)]
localfetcher#3 about to shuffle output of map attempt_local913227038_0001_m_000000_0 decomp: 40 len: 44 to MEMORY
[INFO ][2017/08/03 00:17:46221][org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)]
Read 40 bytes from map-output for attempt_local913227038_0001_m_000000_0
[INFO ][2017/08/03 00:17:46221][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:315)]
closeInMemoryFile -> map-output of size: 40, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->40
[INFO ][2017/08/03 00:17:46222][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)]
EventFetcher is interrupted.. Returning
[INFO ][2017/08/03 00:17:46224][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:46224][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:687)]
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO ][2017/08/03 00:17:46225][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:17:46226][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 1 segments left of total size: 26 bytes
[INFO ][2017/08/03 00:17:46227][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:754)]
Merged 1 segments, 40 bytes to disk to satisfy reduce memory limit
[INFO ][2017/08/03 00:17:46228][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:784)]
Merging 1 files, 44 bytes from disk
[INFO ][2017/08/03 00:17:46228][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:799)]
Merging 0 segments, 0 bytes from memory into reduce
[INFO ][2017/08/03 00:17:46228][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:17:46229][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 1 segments left of total size: 26 bytes
[INFO ][2017/08/03 00:17:46229][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:46270][org.apache.hadoop.mapred.Task.done(Task.java:1038)]
Task:attempt_local913227038_0001_r_000002_0 is done. And is in the process of committing
[INFO ][2017/08/03 00:17:46272][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:46272][org.apache.hadoop.mapred.Task.commit(Task.java:1199)]
Task attempt_local913227038_0001_r_000002_0 is allowed to commit now
[INFO ][2017/08/03 00:17:46273][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:535)]
Saved output of task 'attempt_local913227038_0001_r_000002_0' to file:/home/testuser/eclipse-workspace/HadoopStudy/HadoopStudy/TestData/provinceOutput/_temporary/0/task_local913227038_0001_r_000002
[INFO ][2017/08/03 00:17:46283][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
reduce > reduce
[INFO ][2017/08/03 00:17:46283][org.apache.hadoop.mapred.Task.sendDone(Task.java:1158)]
Task 'attempt_local913227038_0001_r_000002_0' done.
[INFO ][2017/08/03 00:17:46283][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)]
Finishing task: attempt_local913227038_0001_r_000002_0
[INFO ][2017/08/03 00:17:46283][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)]
Starting task: attempt_local913227038_0001_r_000003_0
[INFO ][2017/08/03 00:17:46316][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:108)]
File Output Committer Algorithm version is 1
[INFO ][2017/08/03 00:17:46317][org.apache.hadoop.mapred.Task.initialize(Task.java:612)]
 Using ResourceCalculatorProcessTree : [ ]
[INFO ][2017/08/03 00:17:46317][org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)]
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3010be60
[INFO ][2017/08/03 00:17:46328][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:197)]
MergerManager: memoryLimit=492149152, maxSingleShuffleLimit=123037288, mergeThreshold=324818464, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO ][2017/08/03 00:17:46357][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)]
attempt_local913227038_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO ][2017/08/03 00:17:46364][org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:144)]
localfetcher#4 about to shuffle output of map attempt_local913227038_0001_m_000000_0 decomp: 154 len: 158 to MEMORY
[INFO ][2017/08/03 00:17:46365][org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)]
Read 154 bytes from map-output for attempt_local913227038_0001_m_000000_0
[INFO ][2017/08/03 00:17:46365][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:315)]
closeInMemoryFile -> map-output of size: 154, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->154
[INFO ][2017/08/03 00:17:46376][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)]
EventFetcher is interrupted.. Returning
[INFO ][2017/08/03 00:17:46380][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:46381][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:687)]
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO ][2017/08/03 00:17:46382][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:17:46382][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 1 segments left of total size: 140 bytes
[INFO ][2017/08/03 00:17:46383][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:754)]
Merged 1 segments, 154 bytes to disk to satisfy reduce memory limit
[INFO ][2017/08/03 00:17:46383][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:784)]
Merging 1 files, 158 bytes from disk
[INFO ][2017/08/03 00:17:46383][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:799)]
Merging 0 segments, 0 bytes from memory into reduce
[INFO ][2017/08/03 00:17:46383][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:17:46384][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 1 segments left of total size: 140 bytes
[INFO ][2017/08/03 00:17:46385][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:46440][org.apache.hadoop.mapred.Task.done(Task.java:1038)]
Task:attempt_local913227038_0001_r_000003_0 is done. And is in the process of committing
[INFO ][2017/08/03 00:17:46442][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:46446][org.apache.hadoop.mapred.Task.commit(Task.java:1199)]
Task attempt_local913227038_0001_r_000003_0 is allowed to commit now
[INFO ][2017/08/03 00:17:46446][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:535)]
Saved output of task 'attempt_local913227038_0001_r_000003_0' to file:/home/testuser/eclipse-workspace/HadoopStudy/HadoopStudy/TestData/provinceOutput/_temporary/0/task_local913227038_0001_r_000003
[INFO ][2017/08/03 00:17:46448][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
reduce > reduce
[INFO ][2017/08/03 00:17:46448][org.apache.hadoop.mapred.Task.sendDone(Task.java:1158)]
Task 'attempt_local913227038_0001_r_000003_0' done.
[INFO ][2017/08/03 00:17:46448][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)]
Finishing task: attempt_local913227038_0001_r_000003_0
[INFO ][2017/08/03 00:17:46449][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:302)]
Starting task: attempt_local913227038_0001_r_000004_0
[INFO ][2017/08/03 00:17:46454][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:108)]
File Output Committer Algorithm version is 1
[INFO ][2017/08/03 00:17:46455][org.apache.hadoop.mapred.Task.initialize(Task.java:612)]
 Using ResourceCalculatorProcessTree : [ ]
[INFO ][2017/08/03 00:17:46455][org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)]
Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3ffacd00
[INFO ][2017/08/03 00:17:46457][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:197)]
MergerManager: memoryLimit=492149152, maxSingleShuffleLimit=123037288, mergeThreshold=324818464, ioSortFactor=10, memToMemMergeOutputsThreshold=10
[INFO ][2017/08/03 00:17:46461][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:61)]
attempt_local913227038_0001_r_000004_0 Thread started: EventFetcher for fetching Map Completion Events
[INFO ][2017/08/03 00:17:46466][org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:144)]
localfetcher#5 about to shuffle output of map attempt_local913227038_0001_m_000000_0 decomp: 379 len: 383 to MEMORY
[INFO ][2017/08/03 00:17:46467][org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:100)]
Read 379 bytes from map-output for attempt_local913227038_0001_m_000000_0
[INFO ][2017/08/03 00:17:46493][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeInMemoryFile(MergeManagerImpl.java:315)]
closeInMemoryFile -> map-output of size: 379, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->379
[INFO ][2017/08/03 00:17:46496][org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:76)]
EventFetcher is interrupted.. Returning
[INFO ][2017/08/03 00:17:46496][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:46497][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:687)]
finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
[INFO ][2017/08/03 00:17:46497][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:17:46498][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 1 segments left of total size: 365 bytes
[INFO ][2017/08/03 00:17:46511][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:754)]
Merged 1 segments, 379 bytes to disk to satisfy reduce memory limit
[INFO ][2017/08/03 00:17:46511][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:784)]
Merging 1 files, 383 bytes from disk
[INFO ][2017/08/03 00:17:46511][org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.finalMerge(MergeManagerImpl.java:799)]
Merging 0 segments, 0 bytes from memory into reduce
[INFO ][2017/08/03 00:17:46512][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:606)]
Merging 1 sorted segments
[INFO ][2017/08/03 00:17:46512][org.apache.hadoop.mapred.Merger$MergeQueue.merge(Merger.java:705)]
Down to the last merge-pass, with 1 segments left of total size: 365 bytes
[INFO ][2017/08/03 00:17:46512][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:46549][org.apache.hadoop.mapred.Task.done(Task.java:1038)]
Task:attempt_local913227038_0001_r_000004_0 is done. And is in the process of committing
[INFO ][2017/08/03 00:17:46550][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
1 / 1 copied.
[INFO ][2017/08/03 00:17:46553][org.apache.hadoop.mapred.Task.commit(Task.java:1199)]
Task attempt_local913227038_0001_r_000004_0 is allowed to commit now
[INFO ][2017/08/03 00:17:46554][org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:535)]
Saved output of task 'attempt_local913227038_0001_r_000004_0' to file:/home/testuser/eclipse-workspace/HadoopStudy/HadoopStudy/TestData/provinceOutput/_temporary/0/task_local913227038_0001_r_000004
[INFO ][2017/08/03 00:17:46555][org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(LocalJobRunner.java:591)]
reduce > reduce
[INFO ][2017/08/03 00:17:46556][org.apache.hadoop.mapred.Task.sendDone(Task.java:1158)]
Task 'attempt_local913227038_0001_r_000004_0' done.
[INFO ][2017/08/03 00:17:46556][org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:325)]
Finishing task: attempt_local913227038_0001_r_000004_0
[INFO ][2017/08/03 00:17:46556][org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:456)]
reduce task executor complete.
[INFO ][2017/08/03 00:17:46888][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1367)]
 map 100% reduce 100%
[INFO ][2017/08/03 00:17:46889][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1378)]
Job job_local913227038_0001 completed successfully
[INFO ][2017/08/03 00:17:46946][org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1385)]
Counters: 30
	File System Counters
		FILE: Number of bytes read=18874
		FILE: Number of bytes written=1723074
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=21
		Map output records=21
		Map output bytes=753
		Map output materialized bytes=825
		Input split bytes=159
		Combine input records=0
		Combine output records=0
		Reduce input groups=21
		Reduce shuffle bytes=825
		Reduce input records=21
		Reduce output records=21
		Spilled Records=42
		Shuffled Maps =5
		Failed Shuffles=0
		Merged Map outputs=5
		GC time elapsed (ms)=100
		Total committed heap usage (bytes)=1132986368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=579
	File Output Format Counters 
		Bytes Written=619
